{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d72c37d-086b-4782-b231-3a0b1daf74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from jiwer import wer\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337e89c9-6129-416c-a3d1-fcb7fb0a2f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize string inputs to make more accurate wer counts\n",
    "def pre_jiwer_standardize(any_string):\n",
    "    wer_standardize = jiwer.Compose(\n",
    "    [\n",
    "        jiwer.ToLowerCase(),\n",
    "        jiwer.ExpandCommonEnglishContractions(),\n",
    "        jiwer.RemoveKaldiNonWords(),\n",
    "        jiwer.RemoveWhiteSpace(replace_by_space=True),\n",
    "        jiwer.RemoveMultipleSpaces(),\n",
    "        jiwer.Strip(),\n",
    "    ]\n",
    "    )\n",
    "    any_string = str(any_string).replace(\"neighbourhood\", \"neighborhood\")\n",
    "\n",
    "    return wer_standardize(any_string)\n",
    "\n",
    "\n",
    "# applying transformation for preprocessing prompt/transcript columns\n",
    "def transform_col_text(df, col_name, new_col_name):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.loc[:,new_col_name] = df_copy[col_name].apply(pre_jiwer_standardize)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# creating a new wer getting row-wise error rates for transformed strings in col1, col2\n",
    "def wer_transformed(df, wer_col, col1, col2):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.loc[:, wer_col] = df.apply(lambda x:\n",
    "                                  wer(x[col1], x[col2]), axis=1)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ff349a-7bbe-435c-af53-4260cd904564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "df_orig = pd.read_csv('partic_transcripts.csv')\n",
    "df_expected_preprocessed = transform_col_text(df_orig,\n",
    "                                              'Expected Transcription',\n",
    "                                              'preproc_exp_transc')\n",
    "df_large_preprocessed = transform_col_text(df_expected_preprocessed,\n",
    "                                           'large',\n",
    "                                           'large_preproc')\n",
    "df_base_preprocessed = transform_col_text(df_large_preprocessed,\n",
    "                                           'base',\n",
    "                                           'base_preproc')\n",
    "df_medium_preprocessed = transform_col_text(df_base_preprocessed,\n",
    "                                           'medium',\n",
    "                                           'medium_preproc')\n",
    "df_small_preprocessed = transform_col_text(df_medium_preprocessed,\n",
    "                                           'small',\n",
    "                                           'small_preproc')\n",
    "df_tiny_preprocessed = transform_col_text(df_small_preprocessed,\n",
    "                                           'tiny',\n",
    "                                           'tiny_preproc')\n",
    "\n",
    "df_preproc_final = df_tiny_preprocessed\n",
    "df_preproc_final.head()\n",
    "df_preproc_final.to_csv('preproc_for_wer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46276f11-1215-46e1-8867-c8823228bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding WER\n",
    "df_wer = wer_transformed(df_preproc_final, \n",
    "                         'large_wer', \n",
    "                         'preproc_exp_transc', \n",
    "                         'large_preproc')\n",
    "df_wer = wer_transformed(df_wer, \n",
    "                         'base_wer', \n",
    "                         'preproc_exp_transc', \n",
    "                         'base_preproc')\n",
    "\n",
    "df_wer = wer_transformed(df_wer, \n",
    "                         'medium_wer', \n",
    "                         'preproc_exp_transc', \n",
    "                         'medium_preproc')\n",
    "\n",
    "df_wer = wer_transformed(df_wer, \n",
    "                         'small_wer', \n",
    "                         'preproc_exp_transc', \n",
    "                         'small_preproc')\n",
    "\n",
    "df_wer = wer_transformed(df_wer, \n",
    "                         'tiny_wer', \n",
    "                         'preproc_exp_transc', \n",
    "                         'tiny_preproc')\n",
    "df_wer.head()\n",
    "df_wer.to_csv('wer_oishani.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cd2e0-02eb-409e-bfee-440be1f677e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
