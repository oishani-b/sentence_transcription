{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4280604-4d5a-496e-81c5-2aaeb6e9e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3dc2f8-9beb-455f-83f9-7df3bc7f74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a0e218-12ea-4933-a316-b2e390d607a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>session_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>stimuli_presented</th>\n",
       "      <th>response_type</th>\n",
       "      <th>response_name</th>\n",
       "      <th>response_value</th>\n",
       "      <th>lang_bg_q3_resp</th>\n",
       "      <th>lang_bg_q3_english_only</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>67d94e1a42f12a9364065df2</td>\n",
       "      <td>9e4c7d9ba7377ea14d0e228c38df883deaf62f3f4d1837...</td>\n",
       "      <td>ExpPrompt10</td>\n",
       "      <td>audio-response</td>\n",
       "      <td>ExpPromptResp10</td>\n",
       "      <td>53c7dbc41f259d6f7157d364-12-ExpPromptResp10.mp4</td>\n",
       "      <td>['Other (you may specify in the next slide)']</td>\n",
       "      <td>False</td>\n",
       "      <td>The beige hue on the waters of the loch impres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>67d94e1a42f12a9364065df2</td>\n",
       "      <td>9e4c7d9ba7377ea14d0e228c38df883deaf62f3f4d1837...</td>\n",
       "      <td>DialPrompt3</td>\n",
       "      <td>audio-response</td>\n",
       "      <td>DialPromptResp3</td>\n",
       "      <td>53c7dbc41f259d6f7157d364-13-DialPromptResp3.mp4</td>\n",
       "      <td>['Other (you may specify in the next slide)']</td>\n",
       "      <td>False</td>\n",
       "      <td>She gives it a one of ten when often it deserv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>67d94e1a42f12a9364065df2</td>\n",
       "      <td>9e4c7d9ba7377ea14d0e228c38df883deaf62f3f4d1837...</td>\n",
       "      <td>LocPrompt18</td>\n",
       "      <td>audio-response</td>\n",
       "      <td>LocPromptResp18</td>\n",
       "      <td>53c7dbc41f259d6f7157d364-14-LocPromptResp18.mp4</td>\n",
       "      <td>['Other (you may specify in the next slide)']</td>\n",
       "      <td>False</td>\n",
       "      <td>What da, why you keep laughing?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                session_id  \\\n",
       "0           181         181  67d94e1a42f12a9364065df2   \n",
       "1           182         182  67d94e1a42f12a9364065df2   \n",
       "2           183         183  67d94e1a42f12a9364065df2   \n",
       "\n",
       "                                      participant_id stimuli_presented  \\\n",
       "0  9e4c7d9ba7377ea14d0e228c38df883deaf62f3f4d1837...       ExpPrompt10   \n",
       "1  9e4c7d9ba7377ea14d0e228c38df883deaf62f3f4d1837...       DialPrompt3   \n",
       "2  9e4c7d9ba7377ea14d0e228c38df883deaf62f3f4d1837...       LocPrompt18   \n",
       "\n",
       "    response_type    response_name  \\\n",
       "0  audio-response  ExpPromptResp10   \n",
       "1  audio-response  DialPromptResp3   \n",
       "2  audio-response  LocPromptResp18   \n",
       "\n",
       "                                    response_value  \\\n",
       "0  53c7dbc41f259d6f7157d364-12-ExpPromptResp10.mp4   \n",
       "1  53c7dbc41f259d6f7157d364-13-DialPromptResp3.mp4   \n",
       "2  53c7dbc41f259d6f7157d364-14-LocPromptResp18.mp4   \n",
       "\n",
       "                                 lang_bg_q3_resp  lang_bg_q3_english_only  \\\n",
       "0  ['Other (you may specify in the next slide)']                    False   \n",
       "1  ['Other (you may specify in the next slide)']                    False   \n",
       "2  ['Other (you may specify in the next slide)']                    False   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  The beige hue on the waters of the loch impres...  \n",
       "1  She gives it a one of ten when often it deserv...  \n",
       "2                    What da, why you keep laughing?  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('sample_test_67d9_results.csv')\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55352615-8c58-4c7a-8545-58fa904147ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whisper_turbo_transcribe(wav_audio_path): # sample file: test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-12-ExpPromptResp10.wav\n",
    "    try:\n",
    "        model = whisper.load_model(\"turbo\")\n",
    "        result = model.transcribe(wav_audio_path)\n",
    "        return result[\"text\"]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "701231fe-7d24-404d-a771-8874bf079c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# whisper_turbo_transcribe('test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-12-ExpPromptResp10.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "239f17a2-61fe-46b8-aff7-35c27c4cf014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-13-DialPromptResp3_whisper_turbo.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-12-ExpPromptResp10_whisper_turbo.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-16-HardPromptResp7_whisper_turbo.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-17-LocPromptResp31_whisper_turbo.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-15-ExpPromptResp5_whisper_turbo.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-14-LocPromptResp18_whisper_turbo.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def folder_whisper_turbo_transcribe(folder_wav_audio): # sample folder: test_session-67d9_data/audio_wav\n",
    "    orig_audio_files_list = os.listdir(folder_wav_audio)\n",
    "\n",
    "    for audio_file in orig_audio_files_list:\n",
    "\n",
    "        if audio_file.endswith('.wav'): # to ignore the .ipynb checkpoints\n",
    "            \n",
    "            transcript_txt_file_name = f'{os.path.splitext(audio_file)[0]}_whisper_turbo.txt' \n",
    "            #eg 53c7dbc41f259d6f7157d364-13-DialPromptResp3_whisper_turbo.txt\n",
    "    \n",
    "            if transcript_txt_file_name not in os.listdir(folder_wav_audio):\n",
    "                # checks if transcription already exists, skips if it does\n",
    "    \n",
    "                full_audio_path = os.path.join(folder_wav_audio, audio_file)\n",
    "                # eg test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-13-DialPromptResp3.wav\n",
    "                \n",
    "                transcript = whisper_turbo_transcribe(full_audio_path)\n",
    "                print(f'Successfully transcribed: \\n{full_audio_path}\\n')\n",
    "    \n",
    "                full_transcript_txt_name = os.path.join(folder_wav_audio, transcript_txt_file_name)\n",
    "                # eg test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-13-DialPromptResp3_whisper_turbo.txt\n",
    "    \n",
    "                with open(full_transcript_txt_name, 'a') as transcript_file:\n",
    "                # writing the whisper transcript into the text file\n",
    "                    if transcript != None:\n",
    "                        transcript_file.write(transcript)\n",
    "                    else:\n",
    "                        transcript_file.write('None') \n",
    "                        # accounts for None returns from transcription function\n",
    "\n",
    "            else:\n",
    "                print(f'Transcription exists at: \\n{transcript_txt_file_name}\\n')\n",
    "                    \n",
    "                        \n",
    "folder_whisper_turbo_transcribe('test_session-67d9_data/audio_wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b939970a-a161-46bc-9681-96072b399ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whisper_medium_transcribe(wav_audio_path): # sample file: test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-12-ExpPromptResp10.wav\n",
    "    try:\n",
    "        model = whisper.load_model(\"medium\")\n",
    "        result = model.transcribe(wav_audio_path)\n",
    "        return result[\"text\"]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12447eae-1149-4ab0-88fc-4cfd19602fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [00:18<00:00, 84.1MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The page view on the waters of the Loch impressed all, including the French queen before she heard that symphony again, just as young Arthur wanted.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "whisper_medium_transcribe('test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-12-ExpPromptResp10.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d93e9600-6e12-4bfd-bdaf-ad78421c4bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-13-DialPromptResp3_whisper_medium.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-12-ExpPromptResp10_whisper_medium.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-16-HardPromptResp7_whisper_medium.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-17-LocPromptResp31_whisper_medium.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-15-ExpPromptResp5_whisper_medium.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-14-LocPromptResp18_whisper_medium.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def folder_whisper_medium_transcribe(folder_wav_audio): # sample folder: test_session-67d9_data/audio_wav\n",
    "    orig_audio_files_list = os.listdir(folder_wav_audio)\n",
    "\n",
    "    for audio_file in orig_audio_files_list:\n",
    "\n",
    "        if audio_file.endswith('.wav'): # to ignore the .ipynb checkpoints\n",
    "            \n",
    "            transcript_txt_file_name = f'{os.path.splitext(audio_file)[0]}_whisper_medium.txt' \n",
    "            #eg 53c7dbc41f259d6f7157d364-13-DialPromptResp3_whisper_turbo.txt\n",
    "    \n",
    "            if transcript_txt_file_name not in os.listdir(folder_wav_audio):\n",
    "                # checks if transcription already exists, skips if it does\n",
    "    \n",
    "                full_audio_path = os.path.join(folder_wav_audio, audio_file)\n",
    "                # eg test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-13-DialPromptResp3.wav\n",
    "                \n",
    "                transcript = whisper_medium_transcribe(full_audio_path)\n",
    "                print(f'Successfully transcribed: \\n{full_audio_path}\\n')\n",
    "    \n",
    "                full_transcript_txt_name = os.path.join(folder_wav_audio, transcript_txt_file_name)\n",
    "                # eg test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-13-DialPromptResp3_whisper_medium.txt\n",
    "    \n",
    "                with open(full_transcript_txt_name, 'a') as transcript_file:\n",
    "                # writing the whisper transcript into the text file\n",
    "                    if transcript != None:\n",
    "                        transcript_file.write(transcript)\n",
    "                    else:\n",
    "                        transcript_file.write('None') \n",
    "                        # accounts for None returns from transcription function\n",
    "\n",
    "            else:\n",
    "                print(f'Transcription exists at: \\n{transcript_txt_file_name}\\n')\n",
    "                    \n",
    "                        \n",
    "folder_whisper_medium_transcribe('test_session-67d9_data/audio_wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edc102dd-a762-43c3-b7c7-34e3c156cf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oishanibandopadhyay/whisper-env/lib/python3.12/site-packages/whisper/__init__.py:69: UserWarning: /Users/oishanibandopadhyay/.cache/whisper/large-v3.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████| 2.88G/2.88G [00:35<00:00, 87.7MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-13-DialPromptResp3_whisper_large.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-12-ExpPromptResp10_whisper_large.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-16-HardPromptResp7_whisper_large.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-17-LocPromptResp31_whisper_large.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-15-ExpPromptResp5_whisper_large.txt\n",
      "\n",
      "Transcription exists at: \n",
      "53c7dbc41f259d6f7157d364-14-LocPromptResp18_whisper_large.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# does not work\n",
    "\n",
    "def whisper_large_transcribe(wav_audio_path): # sample file: test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-12-ExpPromptResp10.wav\n",
    "    try:\n",
    "        model = whisper.load_model(\"large\")\n",
    "        result = model.transcribe(wav_audio_path)\n",
    "        return result[\"text\"]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# test\n",
    "whisper_large_transcribe('test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-12-ExpPromptResp10.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa9ae0cb-6390-44a0-8eca-b2264f076c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully transcribed: \n",
      "test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-13-DialPromptResp3.wav\n",
      "\n",
      "Successfully transcribed: \n",
      "test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-12-ExpPromptResp10.wav\n",
      "\n",
      "Successfully transcribed: \n",
      "test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-16-HardPromptResp7.wav\n",
      "\n",
      "Successfully transcribed: \n",
      "test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-17-LocPromptResp31.wav\n",
      "\n",
      "Successfully transcribed: \n",
      "test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-15-ExpPromptResp5.wav\n",
      "\n",
      "Successfully transcribed: \n",
      "test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-14-LocPromptResp18.wav\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def folder_whisper_large_transcribe(folder_wav_audio): # sample folder: test_session-67d9_data/audio_wav\n",
    "    orig_audio_files_list = os.listdir(folder_wav_audio)\n",
    "\n",
    "    for audio_file in orig_audio_files_list:\n",
    "\n",
    "        if audio_file.endswith('.wav'): # to ignore the .ipynb checkpoints\n",
    "            \n",
    "            transcript_txt_file_name = f'{os.path.splitext(audio_file)[0]}_whisper_large.txt' \n",
    "            #eg 53c7dbc41f259d6f7157d364-13-DialPromptResp3_whisper_turbo.txt\n",
    "    \n",
    "            if transcript_txt_file_name not in os.listdir(folder_wav_audio):\n",
    "                # checks if transcription already exists, skips if it does\n",
    "    \n",
    "                full_audio_path = os.path.join(folder_wav_audio, audio_file)\n",
    "                # eg test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-13-DialPromptResp3.wav\n",
    "                \n",
    "                transcript = whisper_large_transcribe(full_audio_path)\n",
    "                print(f'Successfully transcribed: \\n{full_audio_path}\\n')\n",
    "    \n",
    "                full_transcript_txt_name = os.path.join(folder_wav_audio, transcript_txt_file_name)\n",
    "                # eg test_session-67d9_data/audio_wav/53c7dbc41f259d6f7157d364-13-DialPromptResp3_whisper_large.txt\n",
    "    \n",
    "                with open(full_transcript_txt_name, 'a') as transcript_file:\n",
    "                # writing the whisper transcript into the text file\n",
    "                    if transcript != None:\n",
    "                        transcript_file.write(transcript)\n",
    "                    else:\n",
    "                        transcript_file.write('None') \n",
    "                        # accounts for None returns from transcription function\n",
    "\n",
    "            else:\n",
    "                print(f'Transcription exists at: \\n{transcript_txt_file_name}\\n')\n",
    "                    \n",
    "                        \n",
    "folder_whisper_large_transcribe('test_session-67d9_data/audio_wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faedea3f-d142-49fe-a803-dd4aaff9695c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Whisper)",
   "language": "python",
   "name": "whisper-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
