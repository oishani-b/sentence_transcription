{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79b9aab4-b0d1-4a69-8f1f-9f1853f2d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "529c60c3-bae1-430f-8174-9a4bae93fa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence_df = pd.read_csv(\"LASR_sentence_recording_material - forOishani.csv\")\\nsentence_df = sentence_df.rename(columns={\\'Unnamed: 2\\': \\'probability\\'})\\nsentence_df[[\\'sent_num\\', \\'prob_type\\']] = sentence_df[\\'Sentence ID\\'].str.split(\\'_\\', expand=True)\\nsentence_df = sentence_df[[\\'Sentence ID\\', \\'sent_num\\', \\'prob_type\\', \\'Expected Transcription\\', \\'probability\\']]\\nsentence_df.head()'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old sentence info sheet - currently using sentence_info.csv inside sentence_transcription folder/repo\n",
    "'''sentence_df = pd.read_csv(\"LASR_sentence_recording_material - forOishani.csv\")\n",
    "sentence_df = sentence_df.rename(columns={'Unnamed: 2': 'probability'})\n",
    "sentence_df[['sent_num', 'prob_type']] = sentence_df['Sentence ID'].str.split('_', expand=True)\n",
    "sentence_df = sentence_df[['Sentence ID', 'sent_num', 'prob_type', 'Expected Transcription', 'probability']]\n",
    "sentence_df.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "320a726c-ce1d-44e7-a634-d9b638ef2cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>prob_type</th>\n",
       "      <th>probability</th>\n",
       "      <th>reference</th>\n",
       "      <th>expected_transcription</th>\n",
       "      <th>acceptable_transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>high prob</td>\n",
       "      <td>The monkey ate the banana.</td>\n",
       "      <td>the monkey ate the banana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>low prob</td>\n",
       "      <td>The monkey ate the shark.</td>\n",
       "      <td>the monkey ate the shark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>nonword</td>\n",
       "      <td>The runkey ate the shark.</td>\n",
       "      <td>the runkey ate the shark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>high prob</td>\n",
       "      <td>Mom likes to use the elevator instead of the s...</td>\n",
       "      <td>mom likes to use the elevator instead of the s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>nonword</td>\n",
       "      <td>Pom likes to use the elevator instead of the d...</td>\n",
       "      <td>pom likes to use the elevator instead of the d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id sent_num prob_type probability  \\\n",
       "0         1_1        1         1   high prob   \n",
       "1         1_2        1         2    low prob   \n",
       "2         1_3        1         3     nonword   \n",
       "3         2_1        2         1   high prob   \n",
       "4         2_2        2         2     nonword   \n",
       "\n",
       "                                           reference  \\\n",
       "0                         The monkey ate the banana.   \n",
       "1                          The monkey ate the shark.   \n",
       "2                          The runkey ate the shark.   \n",
       "3  Mom likes to use the elevator instead of the s...   \n",
       "4  Pom likes to use the elevator instead of the d...   \n",
       "\n",
       "                              expected_transcription acceptable_transcription  \n",
       "0                          the monkey ate the banana                      NaN  \n",
       "1                           the monkey ate the shark                      NaN  \n",
       "2                           the runkey ate the shark                      NaN  \n",
       "3  mom likes to use the elevator instead of the s...                      NaN  \n",
       "4  pom likes to use the elevator instead of the d...                      NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df = pd.read_csv(\"sentence_info.csv\")\n",
    "sentence_df = sentence_df.rename(columns={'sentence_type': 'probability'})\n",
    "sentence_df[['sent_num', 'prob_type']] = sentence_df['sentence_id'].str.split('_', expand=True)\n",
    "sentence_df = sentence_df[['sentence_id', 'sent_num', 'prob_type', 'probability', 'reference', \n",
    "                           'expected_transcription', 'acceptable_transcription']]\n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30a68e75-39b8-4236-82f7-4f1b7abccebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>prob_type</th>\n",
       "      <th>probability</th>\n",
       "      <th>reference</th>\n",
       "      <th>expected_transcription</th>\n",
       "      <th>acceptable_transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>96_3</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>high prob</td>\n",
       "      <td>In the woods lived a big, growly bear.</td>\n",
       "      <td>in the woods lived a big growly bear</td>\n",
       "      <td>['in the woods lived a big growly beer']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id sent_num prob_type probability  \\\n",
       "287        96_3       96         3   high prob   \n",
       "\n",
       "                                  reference  \\\n",
       "287  In the woods lived a big, growly bear.   \n",
       "\n",
       "                   expected_transcription  \\\n",
       "287  in the woods lived a big growly bear   \n",
       "\n",
       "                     acceptable_transcription  \n",
       "287  ['in the woods lived a big growly beer']  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick check for corrections\n",
    "sentence_df[sentence_df['sentence_id'] == \"96_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c021e25-4842-4ff6-bc1d-4cedcfcfc488",
   "metadata": {},
   "source": [
    "### Getting Low Probability wav Files into Participant Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a776a1f-9b52-4655-8219-8fe55bc868c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 low-prob Sentence IDs\n"
     ]
    }
   ],
   "source": [
    "# get low prob sentences from df\n",
    "low_ids = set(\n",
    "    sentence_df.loc[sentence_df[\"probability\"].str.strip().str.lower().eq(\"low prob\"), \"sentence_id\"]\n",
    "      .astype(str)\n",
    "      .str.strip()\n",
    ")\n",
    "\n",
    "print(f\"Found {len(low_ids)} low-prob Sentence IDs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e253d47a-b1f7-4ce8-897e-1c55c058c81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t1'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t10'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t12'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t13'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t15'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t17'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t18'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t19'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t2'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t20'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t21'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t22'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t23'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t24'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t25'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t26'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t27'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t28'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t3'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t30'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t31'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t32'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t33'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t34'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t35'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t36'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t37'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t38'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t4'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t40'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t41'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t43'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t44'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t45'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t47'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t48'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t49'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t5'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t51'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t52'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t53'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t54'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t55'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t56'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t57'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t58'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t59'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t6'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t60'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t61'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t62'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t63'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t64'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t65'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t66'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t67'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t68'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t69'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t7'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t71'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t72'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t73'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t74'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t75'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t76'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t77'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t78'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t79'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t8'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t80'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t82'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t83'), PosixPath('/Users/cogsci-lasrlab1/Desktop/MTAA_recording/t84')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nparticipant_names = ['t78', 't79',\\n                   't80', 't82',\\n                   't83', 't8']\\n\\nparticipant_dirs = [root / name for name in participant_names]\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find participant directories in root folder\n",
    "root = Path(\"/Users/cogsci-lasrlab1/Desktop/MTAA_recording\")  \n",
    "\n",
    "# commented out to work with new participants only - this is the original code\n",
    "participant_dirs = sorted([p for p in root.iterdir() if p.is_dir() and p.name.startswith(\"t\")])\n",
    "print(participant_dirs)\n",
    "\n",
    "# commented out to re-run all folders\n",
    "# to add new participant prob folders ONLY\n",
    "'''\n",
    "participant_names = ['t78', 't79',\n",
    "                   't80', 't82',\n",
    "                   't83', 't8']\n",
    "\n",
    "participant_dirs = [root / name for name in participant_names]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de840166-e880-4463-9aeb-c04a1b175724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-running\n",
    "# copy matching relevant wav files from the df\n",
    "for pdir in participant_dirs:\n",
    "    out_dir = pdir / f\"{pdir.name}_low_prob\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    copied = 0\n",
    "    for wav_path in pdir.glob(\"*.wav\"):  # only wav files directly inside t1/ etc.\n",
    "        fname = wav_path.name\n",
    "\n",
    "        # Match any low-prob Sentence ID in the filename.\n",
    "        # Using \"sauce_{sid}_\" to avoid accidental partial matches.\n",
    "        if any(f\"sauce_{sid}_\" in fname for sid in low_ids):\n",
    "            shutil.copy2(wav_path, out_dir / wav_path.name)\n",
    "            copied += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11daac8f-a126-4bde-bcff-4be60dba9edf",
   "metadata": {},
   "source": [
    "### Creating probability split folders in each participant folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c527cf3c-fe17-445e-bbed-91781bac5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_ids(prob): # gets you the set of sentence ids for each probability input\n",
    "    prob_ids = set(\n",
    "    sentence_df.loc[sentence_df[\"probability\"].str.strip().str.lower().eq(prob), \"sentence_id\"]\n",
    "      .astype(str)\n",
    "      .str.strip()\n",
    "    )\n",
    "    return prob_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58ce24e6-920a-4c0a-afc2-dc4a5634a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_ids = get_prob_ids(\"high prob\")\n",
    "low_prob_ids = get_prob_ids(\"low prob\")\n",
    "nonword_ids = get_prob_ids(\"nonword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d1fca92-7b36-48e0-8b08-befb2bbb6443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low\n"
     ]
    }
   ],
   "source": [
    "print(\"low prob\".split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "917057bb-d7fc-454a-b150-d0cc18175050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy name matched files regardless of extension\n",
    "# to respective folder for participant\n",
    "def make_prob_folder(participant_dirs, prob):\n",
    "    prob_ids = get_prob_ids(prob)\n",
    "    \n",
    "    for pdir in participant_dirs:\n",
    "        # for low and high prob:\n",
    "        # out_dir = pdir / f\"{pdir.name}_{prob.split()[0]}_{prob.split()[1]}_all\"\n",
    "\n",
    "        # for nonword\n",
    "        out_dir = pdir / f\"{pdir.name}_{prob}_all\"\n",
    "        \n",
    "        out_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "        copied = 0\n",
    "        for path in pdir.iterdir():  # files directly inside t1/ etc.\n",
    "            fname = path.name\n",
    "    \n",
    "            # Match prob and Sentence ID in the filename.\n",
    "            # Using \"sauce_{sid}_\" to avoid accidental partial matches.\n",
    "            if any(f\"sauce_{sid}_\" in fname for sid in prob_ids):\n",
    "                shutil.copy2(path, out_dir / path.name)\n",
    "                copied += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f1407a5-4960-4183-8207-fb08b6c5c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prob_folder(participant_dirs, \"high prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d571191a-4cab-4ba9-a2ed-4ef9eee615dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prob_folder(participant_dirs, \"low prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e5edd3f-6d03-45a6-8361-2570df5afb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prob_folder(participant_dirs, \"nonword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3fb52-0e50-4342-bad6-7d7066fe163b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
