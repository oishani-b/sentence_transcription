{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "install_packages",
   "metadata": {},
   "source": [
    "### Install Required Packages (Run this first if jiwer is not installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if jiwer is not installed\n",
    "# !pip install jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28698c8-f91c-4324-9bca-cab2aa97a528",
   "metadata": {},
   "source": [
    "### Imports for Jiwer and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2e0387-2c87-4d9e-9960-932b38db7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from jiwer import wer\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fb467-258e-49c2-92e6-767c0cef2c22",
   "metadata": {},
   "source": [
    "### Load the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f92c83f9-532a-4611-9d43-a903f14c44ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 51197 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>probability</th>\n",
       "      <th>reference</th>\n",
       "      <th>expected_transcription</th>\n",
       "      <th>acceptable_transcription</th>\n",
       "      <th>large</th>\n",
       "      <th>base</th>\n",
       "      <th>medium</th>\n",
       "      <th>small</th>\n",
       "      <th>tiny</th>\n",
       "      <th>large_preproc</th>\n",
       "      <th>base_preproc</th>\n",
       "      <th>medium_preproc</th>\n",
       "      <th>small_preproc</th>\n",
       "      <th>tiny_preproc</th>\n",
       "      <th>large_wer_list</th>\n",
       "      <th>large_wer_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_25_3_L2_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>25_3</td>\n",
       "      <td>L2</td>\n",
       "      <td>low prob</td>\n",
       "      <td>When I get a cold I have a runny pumpkin.</td>\n",
       "      <td>when i get a cold i have a runny pumpkin</td>\n",
       "      <td>['when i get a cold i have a runny pumpkin']</td>\n",
       "      <td>When I get cold I have a running pumpkin.</td>\n",
       "      <td>When I get cold I have a running pumpkin.</td>\n",
       "      <td>When I get cold I have a runny pumpkin.</td>\n",
       "      <td>When I get cold I have a running pumpkin.</td>\n",
       "      <td>When I get cold I have a running pumpkin.</td>\n",
       "      <td>when i get cold i have a running pumpkin</td>\n",
       "      <td>when i get cold i have a running pumpkin</td>\n",
       "      <td>when i get cold i have a runny pumpkin</td>\n",
       "      <td>when i get cold i have a running pumpkin</td>\n",
       "      <td>when i get cold i have a running pumpkin</td>\n",
       "      <td>[0.2]</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_79_2_L1_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>79_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>nonword</td>\n",
       "      <td>There are 3 tedrooms in their carrot.</td>\n",
       "      <td>there are 3 tedrooms in their carrot</td>\n",
       "      <td>['there are three tedrooms in their carrot', '...</td>\n",
       "      <td>There are three tat rooms in the carrot.</td>\n",
       "      <td>There are three tent rooms in their carrot.</td>\n",
       "      <td>There are three tat rooms in their carriage.</td>\n",
       "      <td>There are three Ted rooms in their carrot.</td>\n",
       "      <td>There are three tat rooms in their carrots.</td>\n",
       "      <td>there are three tat rooms in the carrot</td>\n",
       "      <td>there are three tent rooms in their carrot</td>\n",
       "      <td>there are three tat rooms in their carriage</td>\n",
       "      <td>there are three ted rooms in their carrot</td>\n",
       "      <td>there are three tat rooms in their carrots</td>\n",
       "      <td>[0.42857142857142855, 0.5714285714285714, 0.57...</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_34_1_L2_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>34_1</td>\n",
       "      <td>L2</td>\n",
       "      <td>high prob</td>\n",
       "      <td>At the zoo, I saw a tall giraffe.</td>\n",
       "      <td>at the zoo i saw a tall giraffe</td>\n",
       "      <td>['at the zoo i saw a tall giraffe']</td>\n",
       "      <td>At the zoo I saw a tall giraffe.</td>\n",
       "      <td>At the zoo I saw a tall giraffe.</td>\n",
       "      <td>At the zoo I saw a tall giraffe.</td>\n",
       "      <td>At the zoo I saw a tall giraffe.</td>\n",
       "      <td>At the zoo I saw a tall giraffe.</td>\n",
       "      <td>at the zoo i saw a tall giraffe</td>\n",
       "      <td>at the zoo i saw a tall giraffe</td>\n",
       "      <td>at the zoo i saw a tall giraffe</td>\n",
       "      <td>at the zoo i saw a tall giraffe</td>\n",
       "      <td>at the zoo i saw a tall giraffe</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_3_2_L1_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>3_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>high prob</td>\n",
       "      <td>The king wore a shiny, gold crown</td>\n",
       "      <td>the king wore a shiny gold crown</td>\n",
       "      <td>['the king wore a shiny gold crown']</td>\n",
       "      <td>The king wore a shiny gold crown.</td>\n",
       "      <td>The King wore a shiny gold crown.</td>\n",
       "      <td>The king wore a shiny gold crown.</td>\n",
       "      <td>The king wore a shiny gold crown.</td>\n",
       "      <td>The King wore a shiny gold crown.</td>\n",
       "      <td>the king wore a shiny gold crown</td>\n",
       "      <td>the king wore a shiny gold crown</td>\n",
       "      <td>the king wore a shiny gold crown</td>\n",
       "      <td>the king wore a shiny gold crown</td>\n",
       "      <td>the king wore a shiny gold crown</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_37_2_L1_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>37_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>low prob</td>\n",
       "      <td>Grandma sits on her porch in a bat.</td>\n",
       "      <td>grandma sits on her porch in a bat</td>\n",
       "      <td>['grandma sits on her porch in a bat']</td>\n",
       "      <td>Grandma sits on her porch in a bed.</td>\n",
       "      <td>Grandma sits on her porch in a bed.</td>\n",
       "      <td>Grandma sits on her porch in the bed.</td>\n",
       "      <td>Grandma sits on her porch in the bed.</td>\n",
       "      <td>Grandma sits on her porch in a bed.</td>\n",
       "      <td>grandma sits on her porch in a bed</td>\n",
       "      <td>grandma sits on her porch in a bed</td>\n",
       "      <td>grandma sits on her porch in the bed</td>\n",
       "      <td>grandma sits on her porch in the bed</td>\n",
       "      <td>grandma sits on her porch in a bed</td>\n",
       "      <td>[0.125]</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_name participant_id  \\\n",
       "0  t45_M_EN_SAUCE_block0_sauce_25_3_L2_large-v3.txt            t45   \n",
       "1  t45_M_EN_SAUCE_block0_sauce_79_2_L1_large-v3.txt            t45   \n",
       "2  t45_M_EN_SAUCE_block0_sauce_34_1_L2_large-v3.txt            t45   \n",
       "3   t45_M_EN_SAUCE_block0_sauce_3_2_L1_large-v3.txt            t45   \n",
       "4  t45_M_EN_SAUCE_block0_sauce_37_2_L1_large-v3.txt            t45   \n",
       "\n",
       "  sentence_id Iteration probability  \\\n",
       "0        25_3        L2    low prob   \n",
       "1        79_2        L1     nonword   \n",
       "2        34_1        L2   high prob   \n",
       "3         3_2        L1   high prob   \n",
       "4        37_2        L1    low prob   \n",
       "\n",
       "                                   reference  \\\n",
       "0  When I get a cold I have a runny pumpkin.   \n",
       "1      There are 3 tedrooms in their carrot.   \n",
       "2          At the zoo, I saw a tall giraffe.   \n",
       "3          The king wore a shiny, gold crown   \n",
       "4        Grandma sits on her porch in a bat.   \n",
       "\n",
       "                     expected_transcription  \\\n",
       "0  when i get a cold i have a runny pumpkin   \n",
       "1      there are 3 tedrooms in their carrot   \n",
       "2           at the zoo i saw a tall giraffe   \n",
       "3          the king wore a shiny gold crown   \n",
       "4        grandma sits on her porch in a bat   \n",
       "\n",
       "                            acceptable_transcription  \\\n",
       "0       ['when i get a cold i have a runny pumpkin']   \n",
       "1  ['there are three tedrooms in their carrot', '...   \n",
       "2                ['at the zoo i saw a tall giraffe']   \n",
       "3               ['the king wore a shiny gold crown']   \n",
       "4             ['grandma sits on her porch in a bat']   \n",
       "\n",
       "                                       large  \\\n",
       "0  When I get cold I have a running pumpkin.   \n",
       "1   There are three tat rooms in the carrot.   \n",
       "2           At the zoo I saw a tall giraffe.   \n",
       "3          The king wore a shiny gold crown.   \n",
       "4        Grandma sits on her porch in a bed.   \n",
       "\n",
       "                                          base  \\\n",
       "0    When I get cold I have a running pumpkin.   \n",
       "1  There are three tent rooms in their carrot.   \n",
       "2             At the zoo I saw a tall giraffe.   \n",
       "3            The King wore a shiny gold crown.   \n",
       "4          Grandma sits on her porch in a bed.   \n",
       "\n",
       "                                         medium  \\\n",
       "0       When I get cold I have a runny pumpkin.   \n",
       "1  There are three tat rooms in their carriage.   \n",
       "2              At the zoo I saw a tall giraffe.   \n",
       "3             The king wore a shiny gold crown.   \n",
       "4         Grandma sits on her porch in the bed.   \n",
       "\n",
       "                                        small  \\\n",
       "0   When I get cold I have a running pumpkin.   \n",
       "1  There are three Ted rooms in their carrot.   \n",
       "2            At the zoo I saw a tall giraffe.   \n",
       "3           The king wore a shiny gold crown.   \n",
       "4       Grandma sits on her porch in the bed.   \n",
       "\n",
       "                                          tiny  \\\n",
       "0    When I get cold I have a running pumpkin.   \n",
       "1  There are three tat rooms in their carrots.   \n",
       "2             At the zoo I saw a tall giraffe.   \n",
       "3            The King wore a shiny gold crown.   \n",
       "4          Grandma sits on her porch in a bed.   \n",
       "\n",
       "                              large_preproc  \\\n",
       "0  when i get cold i have a running pumpkin   \n",
       "1   there are three tat rooms in the carrot   \n",
       "2           at the zoo i saw a tall giraffe   \n",
       "3          the king wore a shiny gold crown   \n",
       "4        grandma sits on her porch in a bed   \n",
       "\n",
       "                                 base_preproc  \\\n",
       "0    when i get cold i have a running pumpkin   \n",
       "1  there are three tent rooms in their carrot   \n",
       "2             at the zoo i saw a tall giraffe   \n",
       "3            the king wore a shiny gold crown   \n",
       "4          grandma sits on her porch in a bed   \n",
       "\n",
       "                                medium_preproc  \\\n",
       "0       when i get cold i have a runny pumpkin   \n",
       "1  there are three tat rooms in their carriage   \n",
       "2              at the zoo i saw a tall giraffe   \n",
       "3             the king wore a shiny gold crown   \n",
       "4         grandma sits on her porch in the bed   \n",
       "\n",
       "                               small_preproc  \\\n",
       "0   when i get cold i have a running pumpkin   \n",
       "1  there are three ted rooms in their carrot   \n",
       "2            at the zoo i saw a tall giraffe   \n",
       "3           the king wore a shiny gold crown   \n",
       "4       grandma sits on her porch in the bed   \n",
       "\n",
       "                                 tiny_preproc  \\\n",
       "0    when i get cold i have a running pumpkin   \n",
       "1  there are three tat rooms in their carrots   \n",
       "2             at the zoo i saw a tall giraffe   \n",
       "3            the king wore a shiny gold crown   \n",
       "4          grandma sits on her porch in a bed   \n",
       "\n",
       "                                      large_wer_list  large_wer_min  \n",
       "0                                              [0.2]       0.200000  \n",
       "1  [0.42857142857142855, 0.5714285714285714, 0.57...       0.428571  \n",
       "2                                              [0.0]       0.000000  \n",
       "3                                              [0.0]       0.000000  \n",
       "4                                            [0.125]       0.125000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('third_wer_oishani.csv', index_col=0)\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wer_calculation",
   "metadata": {},
   "source": [
    "### Helper Function to Calculate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wer_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer_for_model(df, model_name):\n",
    "    \"\"\"\n",
    "    Calculate WER list and min WER for a given model.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with preprocessed transcriptions\n",
    "    - model_name: Name of the model (e.g., 'base', 'medium', 'small', 'tiny')\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with added columns: {model_name}_wer_list and {model_name}_wer_min\n",
    "    \"\"\"\n",
    "    preproc_col = f'{model_name}_preproc'\n",
    "    wer_list_col = f'{model_name}_wer_list'\n",
    "    wer_min_col = f'{model_name}_wer_min'\n",
    "    \n",
    "    # Initialize lists to store WER values\n",
    "    wer_lists = []\n",
    "    wer_mins = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        hypothesis = row[preproc_col]\n",
    "        \n",
    "        # Get expected transcription\n",
    "        expected = row['expected_transcription']\n",
    "        \n",
    "        # Get acceptable transcriptions (parse from string if needed)\n",
    "        acceptable = row['acceptable_transcription']\n",
    "        if pd.isna(acceptable):\n",
    "            acceptable_list = []\n",
    "        elif isinstance(acceptable, str):\n",
    "            try:\n",
    "                acceptable_list = ast.literal_eval(acceptable)\n",
    "            except:\n",
    "                acceptable_list = []\n",
    "        else:\n",
    "            acceptable_list = acceptable if isinstance(acceptable, list) else []\n",
    "        \n",
    "        # Combine expected with acceptable transcriptions\n",
    "        all_references = [expected] + acceptable_list\n",
    "        \n",
    "        # Calculate WER for each reference\n",
    "        wer_values = []\n",
    "        for reference in all_references:\n",
    "            if pd.notna(hypothesis) and pd.notna(reference):\n",
    "                wer_value = jiwer.wer(reference, hypothesis)\n",
    "                wer_values.append(wer_value)\n",
    "        \n",
    "        # Store WER list and minimum\n",
    "        wer_lists.append(wer_values)\n",
    "        wer_mins.append(min(wer_values) if wer_values else np.nan)\n",
    "    \n",
    "    # Add columns to dataframe\n",
    "    df[wer_list_col] = wer_lists\n",
    "    df[wer_min_col] = wer_mins\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1",
   "metadata": {},
   "source": [
    "### Step 1: Add WER columns for all models (base, medium, small, tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "step1_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating WER for base...\n",
      "Completed base\n",
      "Calculating WER for medium...\n",
      "Completed medium\n",
      "Calculating WER for small...\n",
      "Completed small\n",
      "Calculating WER for tiny...\n",
      "Completed tiny\n",
      "\n",
      "All model WERs calculated!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>probability</th>\n",
       "      <th>reference</th>\n",
       "      <th>expected_transcription</th>\n",
       "      <th>acceptable_transcription</th>\n",
       "      <th>large</th>\n",
       "      <th>base</th>\n",
       "      <th>...</th>\n",
       "      <th>large_wer_list</th>\n",
       "      <th>large_wer_min</th>\n",
       "      <th>base_wer_list</th>\n",
       "      <th>base_wer_min</th>\n",
       "      <th>medium_wer_list</th>\n",
       "      <th>medium_wer_min</th>\n",
       "      <th>small_wer_list</th>\n",
       "      <th>small_wer_min</th>\n",
       "      <th>tiny_wer_list</th>\n",
       "      <th>tiny_wer_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_25_3_L2_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>25_3</td>\n",
       "      <td>L2</td>\n",
       "      <td>low prob</td>\n",
       "      <td>When I get a cold I have a runny pumpkin.</td>\n",
       "      <td>when i get a cold i have a runny pumpkin</td>\n",
       "      <td>['when i get a cold i have a runny pumpkin']</td>\n",
       "      <td>When I get cold I have a running pumpkin.</td>\n",
       "      <td>When I get cold I have a running pumpkin.</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2]</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[0.2, 0.2]</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[0.1, 0.1]</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>[0.2, 0.2]</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[0.2, 0.2]</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_79_2_L1_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>79_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>nonword</td>\n",
       "      <td>There are 3 tedrooms in their carrot.</td>\n",
       "      <td>there are 3 tedrooms in their carrot</td>\n",
       "      <td>['there are three tedrooms in their carrot', '...</td>\n",
       "      <td>There are three tat rooms in the carrot.</td>\n",
       "      <td>There are three tent rooms in their carrot.</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.42857142857142855, 0.5714285714285714, 0.57...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>[0.42857142857142855, 0.2857142857142857, 0.42...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>[0.5714285714285714, 0.42857142857142855, 0.42...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>[0.42857142857142855, 0.2857142857142857, 0.42...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>[0.5714285714285714, 0.42857142857142855, 0.42...</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_34_1_L2_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>34_1</td>\n",
       "      <td>L2</td>\n",
       "      <td>high prob</td>\n",
       "      <td>At the zoo, I saw a tall giraffe.</td>\n",
       "      <td>at the zoo i saw a tall giraffe</td>\n",
       "      <td>['at the zoo i saw a tall giraffe']</td>\n",
       "      <td>At the zoo I saw a tall giraffe.</td>\n",
       "      <td>At the zoo I saw a tall giraffe.</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_3_2_L1_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>3_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>high prob</td>\n",
       "      <td>The king wore a shiny, gold crown</td>\n",
       "      <td>the king wore a shiny gold crown</td>\n",
       "      <td>['the king wore a shiny gold crown']</td>\n",
       "      <td>The king wore a shiny gold crown.</td>\n",
       "      <td>The King wore a shiny gold crown.</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t45_M_EN_SAUCE_block0_sauce_37_2_L1_large-v3.txt</td>\n",
       "      <td>t45</td>\n",
       "      <td>37_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>low prob</td>\n",
       "      <td>Grandma sits on her porch in a bat.</td>\n",
       "      <td>grandma sits on her porch in a bat</td>\n",
       "      <td>['grandma sits on her porch in a bat']</td>\n",
       "      <td>Grandma sits on her porch in a bed.</td>\n",
       "      <td>Grandma sits on her porch in a bed.</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.125]</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>[0.125, 0.125]</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>[0.25, 0.25]</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>[0.25, 0.25]</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>[0.125, 0.125]</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_name participant_id  \\\n",
       "0  t45_M_EN_SAUCE_block0_sauce_25_3_L2_large-v3.txt            t45   \n",
       "1  t45_M_EN_SAUCE_block0_sauce_79_2_L1_large-v3.txt            t45   \n",
       "2  t45_M_EN_SAUCE_block0_sauce_34_1_L2_large-v3.txt            t45   \n",
       "3   t45_M_EN_SAUCE_block0_sauce_3_2_L1_large-v3.txt            t45   \n",
       "4  t45_M_EN_SAUCE_block0_sauce_37_2_L1_large-v3.txt            t45   \n",
       "\n",
       "  sentence_id Iteration probability  \\\n",
       "0        25_3        L2    low prob   \n",
       "1        79_2        L1     nonword   \n",
       "2        34_1        L2   high prob   \n",
       "3         3_2        L1   high prob   \n",
       "4        37_2        L1    low prob   \n",
       "\n",
       "                                   reference  \\\n",
       "0  When I get a cold I have a runny pumpkin.   \n",
       "1      There are 3 tedrooms in their carrot.   \n",
       "2          At the zoo, I saw a tall giraffe.   \n",
       "3          The king wore a shiny, gold crown   \n",
       "4        Grandma sits on her porch in a bat.   \n",
       "\n",
       "                     expected_transcription  \\\n",
       "0  when i get a cold i have a runny pumpkin   \n",
       "1      there are 3 tedrooms in their carrot   \n",
       "2           at the zoo i saw a tall giraffe   \n",
       "3          the king wore a shiny gold crown   \n",
       "4        grandma sits on her porch in a bat   \n",
       "\n",
       "                            acceptable_transcription  \\\n",
       "0       ['when i get a cold i have a runny pumpkin']   \n",
       "1  ['there are three tedrooms in their carrot', '...   \n",
       "2                ['at the zoo i saw a tall giraffe']   \n",
       "3               ['the king wore a shiny gold crown']   \n",
       "4             ['grandma sits on her porch in a bat']   \n",
       "\n",
       "                                       large  \\\n",
       "0  When I get cold I have a running pumpkin.   \n",
       "1   There are three tat rooms in the carrot.   \n",
       "2           At the zoo I saw a tall giraffe.   \n",
       "3          The king wore a shiny gold crown.   \n",
       "4        Grandma sits on her porch in a bed.   \n",
       "\n",
       "                                          base  ...  \\\n",
       "0    When I get cold I have a running pumpkin.  ...   \n",
       "1  There are three tent rooms in their carrot.  ...   \n",
       "2             At the zoo I saw a tall giraffe.  ...   \n",
       "3            The King wore a shiny gold crown.  ...   \n",
       "4          Grandma sits on her porch in a bed.  ...   \n",
       "\n",
       "                                      large_wer_list large_wer_min  \\\n",
       "0                                              [0.2]      0.200000   \n",
       "1  [0.42857142857142855, 0.5714285714285714, 0.57...      0.428571   \n",
       "2                                              [0.0]      0.000000   \n",
       "3                                              [0.0]      0.000000   \n",
       "4                                            [0.125]      0.125000   \n",
       "\n",
       "                                       base_wer_list base_wer_min  \\\n",
       "0                                         [0.2, 0.2]     0.200000   \n",
       "1  [0.42857142857142855, 0.2857142857142857, 0.42...     0.285714   \n",
       "2                                         [0.0, 0.0]     0.000000   \n",
       "3                                         [0.0, 0.0]     0.000000   \n",
       "4                                     [0.125, 0.125]     0.125000   \n",
       "\n",
       "                                     medium_wer_list medium_wer_min  \\\n",
       "0                                         [0.1, 0.1]       0.100000   \n",
       "1  [0.5714285714285714, 0.42857142857142855, 0.42...       0.428571   \n",
       "2                                         [0.0, 0.0]       0.000000   \n",
       "3                                         [0.0, 0.0]       0.000000   \n",
       "4                                       [0.25, 0.25]       0.250000   \n",
       "\n",
       "                                      small_wer_list small_wer_min  \\\n",
       "0                                         [0.2, 0.2]      0.200000   \n",
       "1  [0.42857142857142855, 0.2857142857142857, 0.42...      0.285714   \n",
       "2                                         [0.0, 0.0]      0.000000   \n",
       "3                                         [0.0, 0.0]      0.000000   \n",
       "4                                       [0.25, 0.25]      0.250000   \n",
       "\n",
       "                                       tiny_wer_list  tiny_wer_min  \n",
       "0                                         [0.2, 0.2]      0.200000  \n",
       "1  [0.5714285714285714, 0.42857142857142855, 0.42...      0.428571  \n",
       "2                                         [0.0, 0.0]      0.000000  \n",
       "3                                         [0.0, 0.0]      0.000000  \n",
       "4                                     [0.125, 0.125]      0.125000  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of models to process (excluding 'large' since it's already done)\n",
    "models = ['base', 'medium', 'small', 'tiny']\n",
    "\n",
    "# Calculate WER for each model\n",
    "for model in models:\n",
    "    print(f\"Calculating WER for {model}...\")\n",
    "    df = calculate_wer_for_model(df, model)\n",
    "    print(f\"Completed {model}\")\n",
    "\n",
    "print(\"\\nAll model WERs calculated!\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "### Step 2: Add column with minimum WER across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "step2_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'min_wer_across_models' column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>large_wer_min</th>\n",
       "      <th>base_wer_min</th>\n",
       "      <th>medium_wer_min</th>\n",
       "      <th>small_wer_min</th>\n",
       "      <th>tiny_wer_min</th>\n",
       "      <th>min_wer_across_models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t45</td>\n",
       "      <td>25_3</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t45</td>\n",
       "      <td>79_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t45</td>\n",
       "      <td>34_1</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t45</td>\n",
       "      <td>3_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t45</td>\n",
       "      <td>37_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t45</td>\n",
       "      <td>90_2</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t45</td>\n",
       "      <td>93_1</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t45</td>\n",
       "      <td>82_3</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t45</td>\n",
       "      <td>43_1</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t45</td>\n",
       "      <td>52_3</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id sentence_id Iteration  large_wer_min  base_wer_min  \\\n",
       "0            t45        25_3        L2       0.200000      0.200000   \n",
       "1            t45        79_2        L1       0.428571      0.285714   \n",
       "2            t45        34_1        L2       0.000000      0.000000   \n",
       "3            t45         3_2        L1       0.000000      0.000000   \n",
       "4            t45        37_2        L1       0.125000      0.125000   \n",
       "5            t45        90_2        L2       0.000000      0.000000   \n",
       "6            t45        93_1        L1       0.166667      0.333333   \n",
       "7            t45        82_3        L1       0.000000      0.000000   \n",
       "8            t45        43_1        L1       0.000000      0.000000   \n",
       "9            t45        52_3        L1       0.100000      0.200000   \n",
       "\n",
       "   medium_wer_min  small_wer_min  tiny_wer_min  min_wer_across_models  \n",
       "0        0.100000       0.200000      0.200000               0.100000  \n",
       "1        0.428571       0.285714      0.428571               0.285714  \n",
       "2        0.000000       0.000000      0.000000               0.000000  \n",
       "3        0.000000       0.000000      0.000000               0.000000  \n",
       "4        0.250000       0.250000      0.125000               0.125000  \n",
       "5        0.000000       0.000000      0.000000               0.000000  \n",
       "6        0.333333       0.333333      0.166667               0.166667  \n",
       "7        0.000000       0.000000      0.000000               0.000000  \n",
       "8        0.000000       0.000000      0.000000               0.000000  \n",
       "9        0.200000       0.100000      0.100000               0.100000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all model names (including large)\n",
    "all_models = ['large', 'base', 'medium', 'small', 'tiny']\n",
    "\n",
    "# Get the min WER column names\n",
    "min_wer_cols = [f'{model}_wer_min' for model in all_models]\n",
    "\n",
    "# Calculate the minimum WER across all models\n",
    "df['min_wer_across_models'] = df[min_wer_cols].min(axis=1)\n",
    "\n",
    "print(\"Added 'min_wer_across_models' column\")\n",
    "df[['participant_id', 'sentence_id', 'Iteration'] + min_wer_cols + ['min_wer_across_models']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "### Step 3: Add 'winning_model' column (model with lowest WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "step3_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'winning_model' column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>min_wer_across_models</th>\n",
       "      <th>winning_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t45</td>\n",
       "      <td>25_3</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t45</td>\n",
       "      <td>79_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t45</td>\n",
       "      <td>34_1</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t45</td>\n",
       "      <td>3_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t45</td>\n",
       "      <td>37_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t45</td>\n",
       "      <td>90_2</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t45</td>\n",
       "      <td>93_1</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t45</td>\n",
       "      <td>82_3</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t45</td>\n",
       "      <td>43_1</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t45</td>\n",
       "      <td>52_3</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id sentence_id Iteration  min_wer_across_models winning_model\n",
       "0            t45        25_3        L2               0.100000        medium\n",
       "1            t45        79_2        L1               0.285714          base\n",
       "2            t45        34_1        L2               0.000000         large\n",
       "3            t45         3_2        L1               0.000000         large\n",
       "4            t45        37_2        L1               0.125000         large\n",
       "5            t45        90_2        L2               0.000000         large\n",
       "6            t45        93_1        L1               0.166667         large\n",
       "7            t45        82_3        L1               0.000000         large\n",
       "8            t45        43_1        L1               0.000000         large\n",
       "9            t45        52_3        L1               0.100000         large"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find which model has the minimum WER for each row\n",
    "def get_winning_model(row):\n",
    "    min_wers = {model: row[f'{model}_wer_min'] for model in all_models}\n",
    "    # Handle NaN values\n",
    "    min_wers = {k: v for k, v in min_wers.items() if pd.notna(v)}\n",
    "    if not min_wers:\n",
    "        return None\n",
    "    return min(min_wers, key=min_wers.get)\n",
    "\n",
    "df['winning_model'] = df.apply(get_winning_model, axis=1)\n",
    "\n",
    "print(\"Added 'winning_model' column\")\n",
    "df[['participant_id', 'sentence_id', 'Iteration', 'min_wer_across_models', 'winning_model']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "### Step 4: Filter out 'nonword' and find lowest WER across all iterations and models\n",
    "\n",
    "filter out 'nonword' probability entries before grouping, so we only analyze 'high prob' and 'low prob' sentences\n",
    "\n",
    "When multiple iterations have the same lowest WER, we select the first iteration in the order: L1, L2, R1P1, R1P2, R2P1, R2P2, etc. For example, if both L1 and L2 have WER=0, we select L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "step4_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 51197 rows\n",
      "After filtering out 'nonword': 34131 rows\n",
      "\n",
      "Probability distribution after filtering:\n",
      "probability\n",
      "high prob    17066\n",
      "low prob     17065\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary by participant and sentence (excluding nonword):\n",
      "   participant_id sentence_id probability unique_iterations  \\\n",
      "0              t1       100_2    low prob          [L2, L1]   \n",
      "1              t1       100_3   high prob          [L2, L1]   \n",
      "2              t1        10_1    low prob          [L1, L2]   \n",
      "3              t1        10_3   high prob          [L2, L1]   \n",
      "4              t1        11_2   high prob          [L2, L1]   \n",
      "5              t1        11_3    low prob          [L2, L1]   \n",
      "6              t1        12_1   high prob          [L1, L2]   \n",
      "7              t1        12_2    low prob          [L2, L1]   \n",
      "8              t1        13_1    low prob          [L1, L2]   \n",
      "9              t1        13_3   high prob          [L2, L1]   \n",
      "10             t1        14_1    low prob          [L1, L2]   \n",
      "11             t1        14_2   high prob          [L2, L1]   \n",
      "12             t1        15_2   high prob          [L2, L1]   \n",
      "13             t1        15_3    low prob          [L2, L1]   \n",
      "14             t1        16_1    low prob          [L1, L2]   \n",
      "15             t1        16_2   high prob          [L2, L1]   \n",
      "16             t1        17_2   high prob          [L2, L1]   \n",
      "17             t1        17_3    low prob          [L2, L1]   \n",
      "18             t1        18_1   high prob          [L2, L1]   \n",
      "19             t1        18_3    low prob          [L1, L2]   \n",
      "\n",
      "    best_wer_across_iterations best_iteration best_model  \n",
      "0                     0.000000             L1      large  \n",
      "1                     0.000000             L1      large  \n",
      "2                     0.166667             L1     medium  \n",
      "3                     0.000000             L1      large  \n",
      "4                     0.000000             L1      large  \n",
      "5                     0.000000             L1      large  \n",
      "6                     0.000000             L1      large  \n",
      "7                     0.000000             L1       base  \n",
      "8                     0.000000             L1      large  \n",
      "9                     0.000000             L1      large  \n",
      "10                    0.000000             L2     medium  \n",
      "11                    0.000000             L1       base  \n",
      "12                    0.000000             L1      large  \n",
      "13                    0.000000             L1      large  \n",
      "14                    0.111111             L1      large  \n",
      "15                    0.111111             L1      large  \n",
      "16                    0.000000             L1      large  \n",
      "17                    0.000000             L1      large  \n",
      "18                    0.000000             L1      large  \n",
      "19                    0.000000             L1      large  \n",
      "\n",
      "Total rows in best_iteration_info: 14382\n",
      "Probability distribution in best_iteration_info:\n",
      "probability\n",
      "low prob     7191\n",
      "high prob    7191\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Added columns:\n",
      "- unique_iterations: List of all iterations for this participant-sentence combination\n",
      "- best_wer_across_iterations: Lowest WER achieved across all iterations and models\n",
      "- best_iteration: Which iteration achieved the best WER\n",
      "- best_model: Which model achieved the best WER\n",
      "\n",
      "Note: These values are calculated only from 'high prob' and 'low prob' entries (nonword excluded)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/p40r243n0sq576lm52j21pqc0000gn/T/ipykernel_64149/3712030813.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_iteration_info = grouped.apply(get_best_iteration_info).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Filter out 'nonword' entries - we only want 'high prob' and 'low prob'\n",
    "df_no_nonword = df[df['probability'] != 'nonword'].copy()\n",
    "\n",
    "print(f\"Original dataset: {len(df)} rows\")\n",
    "print(f\"After filtering out 'nonword': {len(df_no_nonword)} rows\")\n",
    "print(f\"\\nProbability distribution after filtering:\")\n",
    "print(df_no_nonword['probability'].value_counts())\n",
    "\n",
    "# Group by participant_id and sentence_id (without nonwords)\n",
    "grouped = df_no_nonword.groupby(['participant_id', 'sentence_id'])\n",
    "\n",
    "# For each group, find:\n",
    "# 1. List of unique iterations\n",
    "# 2. Minimum WER across all iterations and models\n",
    "# 3. Which iteration and model achieved this minimum\n",
    "# 4. Probability type\n",
    "\n",
    "def get_best_iteration_info(group):\n",
    "    # Get unique iterations\n",
    "    iterations = group['Iteration'].unique().tolist()\n",
    "    \n",
    "    # Find the minimum WER value\n",
    "    min_wer = group['min_wer_across_models'].min()\n",
    "    \n",
    "    # Get all rows with the minimum WER\n",
    "    min_wer_rows = group[group['min_wer_across_models'] == min_wer]\n",
    "    \n",
    "    # If there are multiple rows with same min WER, sort by iteration and take first\n",
    "    # Define iteration order: L1, L2, R1P1, R1P2, R2P1, R2P2, etc.\n",
    "    iteration_order = ['L1', 'L2', 'R1P1', 'R1P2', 'R2P1', 'R2P2', 'R3P1', 'R3P2']\n",
    "    \n",
    "    # Create a mapping for sorting\n",
    "    iteration_rank = {it: i for i, it in enumerate(iteration_order)}\n",
    "    \n",
    "    # Add a rank column for sorting (unknown iterations get high rank)\n",
    "    min_wer_rows_sorted = min_wer_rows.copy()\n",
    "    min_wer_rows_sorted['iteration_rank'] = min_wer_rows_sorted['Iteration'].map(\n",
    "        lambda x: iteration_rank.get(x, 999)\n",
    "    )\n",
    "    \n",
    "    # Sort by iteration rank and take the first row\n",
    "    min_wer_rows_sorted = min_wer_rows_sorted.sort_values('iteration_rank')\n",
    "    min_row = min_wer_rows_sorted.iloc[0]\n",
    "    \n",
    "    return pd.Series({\n",
    "        'probability': min_row['probability'],  # Add probability to summary\n",
    "        'unique_iterations': iterations,\n",
    "        'best_wer_across_iterations': min_row['min_wer_across_models'],\n",
    "        'best_iteration': min_row['Iteration'],\n",
    "        'best_model': min_row['winning_model']\n",
    "    })\n",
    "\n",
    "best_iteration_info = grouped.apply(get_best_iteration_info).reset_index()\n",
    "\n",
    "print(\"\\nSummary by participant and sentence (excluding nonword):\")\n",
    "print(best_iteration_info.head(20))\n",
    "print(f\"\\nTotal rows in best_iteration_info: {len(best_iteration_info)}\")\n",
    "print(f\"Probability distribution in best_iteration_info:\")\n",
    "print(best_iteration_info['probability'].value_counts())\n",
    "\n",
    "# Merge this info back to the main dataframe (all rows including nonword)\n",
    "# Drop the probability column from best_iteration_info before merging to avoid conflicts\n",
    "best_iteration_info_merge = best_iteration_info.drop(columns=['probability'])\n",
    "df = df.merge(best_iteration_info_merge, on=['participant_id', 'sentence_id'], how='left')\n",
    "\n",
    "print(\"\\nAdded columns:\")\n",
    "print(\"- unique_iterations: List of all iterations for this participant-sentence combination\")\n",
    "print(\"- best_wer_across_iterations: Lowest WER achieved across all iterations and models\")\n",
    "print(\"- best_iteration: Which iteration achieved the best WER\")\n",
    "print(\"- best_model: Which model achieved the best WER\")\n",
    "print(\"\\nNote: These values are calculated only from 'high prob' and 'low prob' entries (nonword excluded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tie_break_verify",
   "metadata": {},
   "source": [
    "Examples where multiple iterations have same WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tie_break_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TIE-BREAKING EXAMPLES\n",
      "======================================================================\n",
      "Looking for cases where multiple iterations achieved the same lowest WER...\n",
      "\n",
      "Example 1:\n",
      "  Participant: t1, Sentence: 100_2\n",
      "  Iterations with WER=0.0000: ['L1', 'L2']\n",
      "  Selected iteration: L1\n",
      "\n",
      "Example 2:\n",
      "  Participant: t1, Sentence: 100_3\n",
      "  Iterations with WER=0.0000: ['L1', 'L2']\n",
      "  Selected iteration: L1\n",
      "\n",
      "Example 3:\n",
      "  Participant: t1, Sentence: 10_1\n",
      "  Iterations with WER=0.1667: ['L1', 'L2']\n",
      "  Selected iteration: L1\n",
      "\n",
      "Example 4:\n",
      "  Participant: t1, Sentence: 10_3\n",
      "  Iterations with WER=0.0000: ['L1', 'L2']\n",
      "  Selected iteration: L1\n",
      "\n",
      "Example 5:\n",
      "  Participant: t1, Sentence: 11_2\n",
      "  Iterations with WER=0.0000: ['L1', 'L2']\n",
      "  Selected iteration: L1\n",
      "\n",
      "Total cases with ties: 11989\n",
      "In all 11989 cases, the earliest iteration (L1 < L2 < R1P1 < ...) was selected.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Find cases where multiple iterations have the same best WER\n",
    "print(\"=\" * 70)\n",
    "print(\"TIE-BREAKING EXAMPLES\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Looking for cases where multiple iterations achieved the same lowest WER...\\n\")\n",
    "\n",
    "# Check in the filtered data\n",
    "ties_found = 0\n",
    "for (participant, sentence), group in df_no_nonword.groupby(['participant_id', 'sentence_id']):\n",
    "    min_wer = group['min_wer_across_models'].min()\n",
    "    iterations_with_min = group[group['min_wer_across_models'] == min_wer]['Iteration'].unique()\n",
    "    \n",
    "    if len(iterations_with_min) > 1:\n",
    "        ties_found += 1\n",
    "        if ties_found <= 5:  # Show first 5 examples\n",
    "            best_iter = best_iteration_info[\n",
    "                (best_iteration_info['participant_id'] == participant) & \n",
    "                (best_iteration_info['sentence_id'] == sentence)\n",
    "            ]['best_iteration'].values[0]\n",
    "            \n",
    "            print(f\"Example {ties_found}:\")\n",
    "            print(f\"  Participant: {participant}, Sentence: {sentence}\")\n",
    "            print(f\"  Iterations with WER={min_wer:.4f}: {sorted(iterations_with_min)}\")\n",
    "            print(f\"  Selected iteration: {best_iter}\")\n",
    "            print()\n",
    "\n",
    "print(f\"Total cases with ties: {ties_found}\")\n",
    "if ties_found == 0:\n",
    "    print(\"No ties found - each participant-sentence combination has a unique best iteration.\")\n",
    "else:\n",
    "    print(f\"In all {ties_found} cases, the earliest iteration (L1 < L2 < R1P1 < ...) was selected.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify",
   "metadata": {},
   "source": [
    "Check the new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "verify_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of data with all new columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>probability</th>\n",
       "      <th>large_wer_min</th>\n",
       "      <th>base_wer_min</th>\n",
       "      <th>medium_wer_min</th>\n",
       "      <th>small_wer_min</th>\n",
       "      <th>tiny_wer_min</th>\n",
       "      <th>min_wer_across_models</th>\n",
       "      <th>winning_model</th>\n",
       "      <th>unique_iterations</th>\n",
       "      <th>best_wer_across_iterations</th>\n",
       "      <th>best_iteration</th>\n",
       "      <th>best_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t45</td>\n",
       "      <td>25_3</td>\n",
       "      <td>L2</td>\n",
       "      <td>low prob</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>medium</td>\n",
       "      <td>[L2, R1P2, L1, R1P1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t45</td>\n",
       "      <td>79_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>nonword</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>base</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t45</td>\n",
       "      <td>34_1</td>\n",
       "      <td>L2</td>\n",
       "      <td>high prob</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "      <td>[L2, L1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t45</td>\n",
       "      <td>3_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>high prob</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "      <td>[L1, L2]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t45</td>\n",
       "      <td>37_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>low prob</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>large</td>\n",
       "      <td>[L1, L2]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t45</td>\n",
       "      <td>90_2</td>\n",
       "      <td>L2</td>\n",
       "      <td>high prob</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "      <td>[L2, L1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t45</td>\n",
       "      <td>93_1</td>\n",
       "      <td>L1</td>\n",
       "      <td>nonword</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t45</td>\n",
       "      <td>82_3</td>\n",
       "      <td>L1</td>\n",
       "      <td>low prob</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "      <td>[L1, L2]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t45</td>\n",
       "      <td>43_1</td>\n",
       "      <td>L1</td>\n",
       "      <td>low prob</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "      <td>[L1, L2]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t45</td>\n",
       "      <td>52_3</td>\n",
       "      <td>L1</td>\n",
       "      <td>nonword</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>t45</td>\n",
       "      <td>40_2</td>\n",
       "      <td>L2</td>\n",
       "      <td>nonword</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t45</td>\n",
       "      <td>56_1</td>\n",
       "      <td>R1P1</td>\n",
       "      <td>high prob</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "      <td>[R1P1, L2, R1P2, L1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t45</td>\n",
       "      <td>81_2</td>\n",
       "      <td>L1</td>\n",
       "      <td>high prob</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>large</td>\n",
       "      <td>[L1, L2]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t45</td>\n",
       "      <td>82_1</td>\n",
       "      <td>L2</td>\n",
       "      <td>nonword</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t45</td>\n",
       "      <td>93_3</td>\n",
       "      <td>L2</td>\n",
       "      <td>high prob</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>large</td>\n",
       "      <td>[L2, L1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>L1</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id sentence_id Iteration probability  large_wer_min  \\\n",
       "0             t45        25_3        L2    low prob       0.200000   \n",
       "1             t45        79_2        L1     nonword       0.428571   \n",
       "2             t45        34_1        L2   high prob       0.000000   \n",
       "3             t45         3_2        L1   high prob       0.000000   \n",
       "4             t45        37_2        L1    low prob       0.125000   \n",
       "5             t45        90_2        L2   high prob       0.000000   \n",
       "6             t45        93_1        L1     nonword       0.166667   \n",
       "7             t45        82_3        L1    low prob       0.000000   \n",
       "8             t45        43_1        L1    low prob       0.000000   \n",
       "9             t45        52_3        L1     nonword       0.100000   \n",
       "10            t45        40_2        L2     nonword       0.166667   \n",
       "11            t45        56_1      R1P1   high prob       0.000000   \n",
       "12            t45        81_2        L1   high prob       0.125000   \n",
       "13            t45        82_1        L2     nonword       0.142857   \n",
       "14            t45        93_3        L2   high prob       0.000000   \n",
       "\n",
       "    base_wer_min  medium_wer_min  small_wer_min  tiny_wer_min  \\\n",
       "0       0.200000        0.100000       0.200000      0.200000   \n",
       "1       0.285714        0.428571       0.285714      0.428571   \n",
       "2       0.000000        0.000000       0.000000      0.000000   \n",
       "3       0.000000        0.000000       0.000000      0.000000   \n",
       "4       0.125000        0.250000       0.250000      0.125000   \n",
       "5       0.000000        0.000000       0.000000      0.000000   \n",
       "6       0.333333        0.333333       0.333333      0.166667   \n",
       "7       0.000000        0.000000       0.000000      0.000000   \n",
       "8       0.000000        0.000000       0.000000      0.000000   \n",
       "9       0.200000        0.200000       0.100000      0.100000   \n",
       "10      0.500000        0.500000       0.666667      0.666667   \n",
       "11      0.166667        0.000000       0.000000      0.250000   \n",
       "12      0.250000        0.125000       0.125000      0.250000   \n",
       "13      0.142857        0.142857       0.142857      0.142857   \n",
       "14      0.666667        0.333333       0.500000      0.500000   \n",
       "\n",
       "    min_wer_across_models winning_model     unique_iterations  \\\n",
       "0                0.100000        medium  [L2, R1P2, L1, R1P1]   \n",
       "1                0.285714          base                   NaN   \n",
       "2                0.000000         large              [L2, L1]   \n",
       "3                0.000000         large              [L1, L2]   \n",
       "4                0.125000         large              [L1, L2]   \n",
       "5                0.000000         large              [L2, L1]   \n",
       "6                0.166667         large                   NaN   \n",
       "7                0.000000         large              [L1, L2]   \n",
       "8                0.000000         large              [L1, L2]   \n",
       "9                0.100000         large                   NaN   \n",
       "10               0.166667         large                   NaN   \n",
       "11               0.000000         large  [R1P1, L2, R1P2, L1]   \n",
       "12               0.125000         large              [L1, L2]   \n",
       "13               0.142857         large                   NaN   \n",
       "14               0.000000         large              [L2, L1]   \n",
       "\n",
       "    best_wer_across_iterations best_iteration best_model  \n",
       "0                        0.000             L1      large  \n",
       "1                          NaN            NaN        NaN  \n",
       "2                        0.000             L1      large  \n",
       "3                        0.000             L1      large  \n",
       "4                        0.125             L1      large  \n",
       "5                        0.000             L1      large  \n",
       "6                          NaN            NaN        NaN  \n",
       "7                        0.000             L1      large  \n",
       "8                        0.000             L1      large  \n",
       "9                          NaN            NaN        NaN  \n",
       "10                         NaN            NaN        NaN  \n",
       "11                       0.000             L1      large  \n",
       "12                       0.125             L1      large  \n",
       "13                         NaN            NaN        NaN  \n",
       "14                       0.000             L1      large  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a sample with all the new columns\n",
    "cols_to_show = [\n",
    "    'participant_id', 'sentence_id', 'Iteration', 'probability',\n",
    "    'large_wer_min', 'base_wer_min', 'medium_wer_min', 'small_wer_min', 'tiny_wer_min',\n",
    "    'min_wer_across_models', 'winning_model',\n",
    "    'unique_iterations', 'best_wer_across_iterations', 'best_iteration', 'best_model'\n",
    "]\n",
    "\n",
    "print(\"Sample of data with all new columns:\")\n",
    "df[cols_to_show].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filter_prob",
   "metadata": {},
   "source": [
    "### Filter for only 'high prob' and 'low prob' (as mentioned in description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "filter_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 51197 rows\n",
      "Filtered dataset (high prob + low prob only): 34131 rows\n",
      "\n",
      "Probability distribution in filtered data:\n",
      "probability\n",
      "high prob    17066\n",
      "low prob     17065\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create filtered dataframe\n",
    "df_filtered = df[df['probability'].isin(['high prob', 'low prob'])].copy()\n",
    "\n",
    "print(f\"Original dataset: {len(df)} rows\")\n",
    "print(f\"Filtered dataset (high prob + low prob only): {len(df_filtered)} rows\")\n",
    "print(f\"\\nProbability distribution in filtered data:\")\n",
    "print(df_filtered['probability'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_stats",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "summary_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean WER by model:\n",
      "large: 0.1649\n",
      "base: 0.2071\n",
      "medium: 0.1302\n",
      "small: 0.1563\n",
      "tiny: 0.2461\n",
      "\n",
      "Winning model distribution (all data):\n",
      "winning_model\n",
      "large     41661\n",
      "medium     3749\n",
      "base       3072\n",
      "small      1762\n",
      "tiny        953\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Winning model distribution (filtered - high prob + low prob only):\n",
      "winning_model\n",
      "large     29406\n",
      "medium     1912\n",
      "base       1530\n",
      "small       819\n",
      "tiny        464\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for each model\n",
    "print(\"Mean WER by model:\")\n",
    "for model in all_models:\n",
    "    mean_wer = df[f'{model}_wer_min'].mean()\n",
    "    print(f\"{model}: {mean_wer:.4f}\")\n",
    "\n",
    "print(\"\\nWinning model distribution (all data):\")\n",
    "print(df['winning_model'].value_counts())\n",
    "\n",
    "print(\"\\nWinning model distribution (filtered - high prob + low prob only):\")\n",
    "print(df_filtered['winning_model'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_summary",
   "metadata": {},
   "source": [
    "### Verify Summary Counts - Check for 72 participants with 100 high prob + 100 low prob each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_summary_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFICATION: Best Iteration Summary (HIGH PROB + LOW PROB ONLY)\n",
      "======================================================================\n",
      "\n",
      "Total rows in best_iteration_info: 14382\n",
      "This represents unique participant Ã— sentence combinations (excluding nonword)\n",
      "\n",
      "Unique participants: 72\n",
      "\n",
      "======================================================================\n",
      "Probability Distribution in Summary\n",
      "======================================================================\n",
      "probability\n",
      "low prob     7191\n",
      "high prob    7191\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ“ Confirmed: No 'nonword' entries in summary (as expected)\n",
      "\n",
      "Total sentences: 14382\n",
      "Expected if 72 participants Ã— 200 sentences: 14400 = 14,400\n",
      "\n",
      "======================================================================\n",
      "Per Participant Breakdown\n",
      "======================================================================\n",
      "\n",
      "First 10 participants:\n",
      "probability     high prob  low prob  total\n",
      "participant_id                            \n",
      "t1                    100       100    200\n",
      "t10                   100       100    200\n",
      "t12                   100       100    200\n",
      "t13                   100       100    200\n",
      "t15                   100       100    200\n",
      "t17                   100       100    200\n",
      "t18                   100       100    200\n",
      "t19                   100       100    200\n",
      "t2                    100       100    200\n",
      "t20                   100       100    200\n",
      "\n",
      "======================================================================\n",
      "Statistics Across All Participants\n",
      "======================================================================\n",
      "\n",
      "High prob sentences per participant:\n",
      "  Mean: 99.88\n",
      "  Std: 1.06\n",
      "  Min: 91\n",
      "  Max: 100\n",
      "  Participants with exactly 100 high prob: 71/72\n",
      "\n",
      "Low prob sentences per participant:\n",
      "  Mean: 99.88\n",
      "  Std: 1.06\n",
      "  Min: 91\n",
      "  Max: 100\n",
      "  Participants with exactly 100 low prob: 71/72\n",
      "\n",
      "======================================================================\n",
      "IDEAL PARTICIPANT CHECK: 100 high prob + 100 low prob = 200 total\n",
      "======================================================================\n",
      "\n",
      "Participants with exactly 100 high prob + 100 low prob: 71/72\n",
      "âš  1 participants do NOT have 100+100 distribution\n",
      "\n",
      "======================================================================\n",
      "PARTICIPANTS WITHOUT 100 HIGH PROB + 100 LOW PROB\n",
      "======================================================================\n",
      "\n",
      "Found 1 participants with non-standard counts:\n",
      "\n",
      "probability     high prob  low prob  total\n",
      "participant_id                            \n",
      "t51                    91        91    182\n",
      "\n",
      "======================================================================\n",
      "Problematic Participants Summary:\n",
      "  t51: 91 high prob, 91 low prob (total: 182)\n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY\n",
      "======================================================================\n",
      "Total participants: 72\n",
      "Total sentences in summary: 14382\n",
      "Expected (72 Ã— 200): 14,400\n",
      "âš  Difference from expected: -18 sentences\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of best_iteration_info\n",
    "print(\"=\" * 70)\n",
    "print(\"VERIFICATION: Best Iteration Summary (HIGH PROB + LOW PROB ONLY)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTotal rows in best_iteration_info: {len(best_iteration_info)}\")\n",
    "print(f\"This represents unique participant Ã— sentence combinations (excluding nonword)\")\n",
    "\n",
    "# Count unique participants\n",
    "unique_participants = best_iteration_info['participant_id'].nunique()\n",
    "print(f\"\\nUnique participants: {unique_participants}\")\n",
    "\n",
    "# Check probability distribution in best_iteration_info\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Probability Distribution in Summary\")\n",
    "print(\"=\" * 70)\n",
    "prob_counts = best_iteration_info['probability'].value_counts()\n",
    "print(prob_counts)\n",
    "\n",
    "\n",
    "print(f\"\\nTotal sentences: {len(best_iteration_info)}\")\n",
    "print(f\"Expected if 72 participants Ã— 200 sentences: {72 * 200} = 14,400\")\n",
    "\n",
    "# Detailed per-participant breakdown\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Per Participant Breakdown\")\n",
    "print(\"=\" * 70)\n",
    "participant_prob_counts = best_iteration_info.groupby(['participant_id', 'probability']).size().unstack(fill_value=0)\n",
    "\n",
    "# Add total column\n",
    "participant_prob_counts['total'] = participant_prob_counts.sum(axis=1)\n",
    "\n",
    "print(f\"\\nFirst 10 participants:\")\n",
    "print(participant_prob_counts.head(10))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Statistics Across All Participants\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'high prob' in participant_prob_counts.columns:\n",
    "    high_prob_stats = participant_prob_counts['high prob'].describe()\n",
    "    print(f\"\\nHigh prob sentences per participant:\")\n",
    "    print(f\"  Mean: {high_prob_stats['mean']:.2f}\")\n",
    "    print(f\"  Std: {high_prob_stats['std']:.2f}\")\n",
    "    print(f\"  Min: {high_prob_stats['min']:.0f}\")\n",
    "    print(f\"  Max: {high_prob_stats['max']:.0f}\")\n",
    "    participants_with_100_high = (participant_prob_counts['high prob'] == 100).sum()\n",
    "    print(f\"  Participants with exactly 100 high prob: {participants_with_100_high}/{unique_participants}\")\n",
    "\n",
    "if 'low prob' in participant_prob_counts.columns:\n",
    "    low_prob_stats = participant_prob_counts['low prob'].describe()\n",
    "    print(f\"\\nLow prob sentences per participant:\")\n",
    "    print(f\"  Mean: {low_prob_stats['mean']:.2f}\")\n",
    "    print(f\"  Std: {low_prob_stats['std']:.2f}\")\n",
    "    print(f\"  Min: {low_prob_stats['min']:.0f}\")\n",
    "    print(f\"  Max: {low_prob_stats['max']:.0f}\")\n",
    "    participants_with_100_low = (participant_prob_counts['low prob'] == 100).sum()\n",
    "    print(f\"  Participants with exactly 100 low prob: {participants_with_100_low}/{unique_participants}\")\n",
    "\n",
    "# Check for participants with exactly 100 + 100\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"IDEAL PARTICIPANT CHECK: 100 high prob + 100 low prob = 200 total\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'high prob' in participant_prob_counts.columns and 'low prob' in participant_prob_counts.columns:\n",
    "    ideal_participants = (\n",
    "        (participant_prob_counts['high prob'] == 100) & \n",
    "        (participant_prob_counts['low prob'] == 100) &\n",
    "        (participant_prob_counts['total'] == 200)\n",
    "    )\n",
    "    num_ideal = ideal_participants.sum()\n",
    "    print(f\"\\nParticipants with exactly 100 high prob + 100 low prob: {num_ideal}/{unique_participants}\")\n",
    "    \n",
    "    if num_ideal == 72:\n",
    "        print(\"âœ“ Perfect! All 72 participants have the expected distribution!\")\n",
    "    elif num_ideal == unique_participants:\n",
    "        print(f\"âœ“ All {unique_participants} participants have the expected distribution!\")\n",
    "    else:\n",
    "        print(f\"âš  {unique_participants - num_ideal} participants do NOT have 100+100 distribution\")\n",
    "\n",
    "# Identify problematic participants\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PARTICIPANTS WITHOUT 100 HIGH PROB + 100 LOW PROB\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'high prob' in participant_prob_counts.columns and 'low prob' in participant_prob_counts.columns:\n",
    "    non_ideal_participants = participant_prob_counts[\n",
    "        (participant_prob_counts['high prob'] != 100) | \n",
    "        (participant_prob_counts['low prob'] != 100)\n",
    "    ]\n",
    "    \n",
    "    if len(non_ideal_participants) > 0:\n",
    "        print(f\"\\nFound {len(non_ideal_participants)} participants with non-standard counts:\\n\")\n",
    "        print(non_ideal_participants)\n",
    "        \n",
    "        # Save list of problematic participants\n",
    "        problematic_list = non_ideal_participants.reset_index()[['participant_id', 'high prob', 'low prob', 'total']]\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"Problematic Participants Summary:\")\n",
    "        for idx, row in problematic_list.iterrows():\n",
    "            print(f\"  {row['participant_id']}: {row['high prob']} high prob, {row['low prob']} low prob (total: {row['total']})\")\n",
    "    else:\n",
    "        print(\"\\nâœ“ All participants have exactly 100 high prob + 100 low prob!\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total participants: {unique_participants}\")\n",
    "print(f\"Total sentences in summary: {len(best_iteration_info)}\")\n",
    "print(f\"Expected (72 Ã— 200): 14,400\")\n",
    "if unique_participants == 72 and len(best_iteration_info) == 14400:\n",
    "    print(\"âœ“ Counts match expectation perfectly!\")\n",
    "elif len(best_iteration_info) == 14400:\n",
    "    print(f\"âœ“ Sentence count matches! ({unique_participants} participants found)\")\n",
    "else:\n",
    "    diff = len(best_iteration_info) - 14400\n",
    "    print(f\"âš  Difference from expected: {diff:+d} sentences\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_results",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "save_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary to: wer_summary_by_participant_sentence.csv\n",
      "  (Contains 14382 rows = participant Ã— sentence combinations)\n",
      "  (Only includes 'high prob' and 'low prob' sentences - nonword excluded)\n",
      "\n",
      "Saved problematic participants to: participants_with_non_standard_counts.csv\n",
      "  (1 participants do not have exactly 100 high + 100 low)\n",
      "\n",
      "All files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('final_wer_all.csv', index=False)\n",
    "\n",
    "# Save the filtered dataset (high prob + low prob only)\n",
    "df_filtered.to_csv('final_wer_high_low_only.csv', index=False)\n",
    "\n",
    "# Save the summary by participant and sentence (high prob + low prob only)\n",
    "best_iteration_info.to_csv('final_wer_summary_by_participant_sentence.csv', index=False)\n",
    "print(\"Saved summary to: wer_summary_by_participant_sentence.csv\")\n",
    "print(f\"  (Contains {len(best_iteration_info)} rows = participant Ã— sentence combinations)\")\n",
    "print(f\"  (Only includes 'high prob' and 'low prob' sentences - nonword excluded)\")\n",
    "\n",
    "# Save problematic participants list if any exist\n",
    "if 'high prob' in participant_prob_counts.columns and 'low prob' in participant_prob_counts.columns:\n",
    "    non_ideal = participant_prob_counts[\n",
    "        (participant_prob_counts['high prob'] != 100) | \n",
    "        (participant_prob_counts['low prob'] != 100)\n",
    "    ]\n",
    "    if len(non_ideal) > 0:\n",
    "        problematic_df = non_ideal.reset_index()\n",
    "        problematic_df.to_csv('participants_with_non_standard_counts.csv', index=False)\n",
    "        print(f\"\\nSaved problematic participants to: participants_with_non_standard_counts.csv\")\n",
    "        print(f\"  ({len(non_ideal)} participants do not have exactly 100 high + 100 low)\")\n",
    "    else:\n",
    "        print(\"\\nâœ“ All participants have exactly 100 high prob + 100 low prob!\")\n",
    "\n",
    "print(\"\\nAll files saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "column_explanation",
   "metadata": {},
   "source": [
    "### New Column Descriptions\n",
    "\n",
    "**For each model (base, medium, small, tiny):**\n",
    "- `{model}_wer_list`: List of WER values comparing the model's transcription to all acceptable references\n",
    "- `{model}_wer_min`: Minimum WER from the list (best match)\n",
    "\n",
    "**Cross-model comparisons:**\n",
    "- `min_wer_across_models`: The lowest WER achieved by any model for this row\n",
    "- `winning_model`: Name of the model that achieved the lowest WER\n",
    "\n",
    "**Iteration-level analysis:**\n",
    "- `unique_iterations`: List of all iterations for this participant-sentence combination\n",
    "- `best_wer_across_iterations`: The lowest WER across all iterations and all models\n",
    "- `best_iteration`: Which iteration achieved the best WER\n",
    "- `best_model`: Which model achieved the best WER (in the best iteration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs219",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
